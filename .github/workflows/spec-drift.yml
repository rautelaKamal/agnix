# Spec Drift Sentinel
# Monitors upstream specification sources for changes that may require rule updates.
# See .github/spec-baselines.json for tracked sources.

name: Spec Drift Sentinel

on:
  schedule:
    # S-tier: Weekly on Sunday at midnight UTC
    - cron: '0 0 * * 0'
    # A-tier: Weekly on Wednesday at midnight UTC (staggered from S-tier)
    - cron: '0 0 * * 3'
  workflow_dispatch:
    inputs:
      update_baselines:
        description: 'Update baseline hashes (run after reviewing changes)'
        required: false
        type: boolean
        default: false
      tier:
        description: 'Which tier to check'
        required: false
        type: choice
        options:
          - all
          - s-tier
          - a-tier
        default: all

permissions:
  contents: read
  issues: write

jobs:
  check-drift:
    name: Check for spec drift
    runs-on: ubuntu-latest
    outputs:
      drift_detected: ${{ steps.drift-check.outputs.drift_detected }}
      drift_sources: ${{ steps.drift-check.outputs.drift_sources }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4

      - name: Check spec sources for drift
        id: drift-check
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          UPDATE_BASELINES: ${{ inputs.update_baselines || 'false' }}
          TIER_FILTER: ${{ inputs.tier || 'all' }}
          SCHEDULE_CRON: ${{ github.event.schedule }}
        run: |
          set -euo pipefail

          BASELINES_FILE=".github/spec-baselines.json"

          # Validate JSON structure
          if ! jq -e '.sources["s-tier"] and .sources["a-tier"]' "$BASELINES_FILE" > /dev/null 2>&1; then
            echo "ERROR: Invalid spec-baselines.json structure"
            exit 1
          fi

          DRIFT_DETECTED=false
          DRIFT_REPORT=""
          NEW_HASHES=""
          DRIFT_SOURCES_JSON="[]"

          # Determine which tiers to check based on trigger
          check_s_tier=false
          check_a_tier=false

          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            case "$TIER_FILTER" in
              s-tier) check_s_tier=true ;;
              a-tier) check_a_tier=true ;;
              all) check_s_tier=true; check_a_tier=true ;;
            esac
          elif [[ "${{ github.event_name }}" == "schedule" ]]; then
            # Each cron schedule triggers a separate workflow run
            # SCHEDULE_CRON contains the specific cron that triggered THIS run
            # Weekly schedule (Sunday midnight UTC) = S-tier sources
            if [[ "$SCHEDULE_CRON" == "0 0 * * 0" ]]; then
              check_s_tier=true
            fi
            # Weekly schedule (Wednesday midnight UTC) = A-tier sources
            if [[ "$SCHEDULE_CRON" == "0 0 * * 3" ]]; then
              check_a_tier=true
            fi
          else
            check_s_tier=true
            check_a_tier=true
          fi

          echo "Checking S-tier: $check_s_tier"
          echo "Checking A-tier: $check_a_tier"

          # Function to normalize content for consistent hashing
          normalize_content() {
            # Remove extra whitespace, normalize line endings
            tr -s '[:space:]' ' ' | sed 's/^ //;s/ $//'
          }

          # Function to compute hash of URL content
          compute_hash() {
            local url="$1"
            local content
            local hash

            # Validate URL is https
            if [[ ! "$url" =~ ^https:// ]]; then
              echo "INVALID_URL"
              return
            fi

            # Fetch with curl, follow redirects, timeout after 30s
            # Use separate variable for exit code to avoid partial content issues
            local exit_code
            content=$(curl -fsSL --max-time 30 "$url" 2>/dev/null) && exit_code=0 || exit_code=$?

            if [[ $exit_code -ne 0 ]]; then
              echo "FETCH_FAILED"
              return
            fi

            # Normalize and hash
            hash=$(echo "$content" | normalize_content | sha256sum | cut -d' ' -f1)
            echo "$hash"
          }

          # Function to fetch GitHub diff for a repo
          fetch_github_diff() {
            local repo="$1"
            local diff_output=""

            # Get recent commits (last 7 days)
            local since_date
            since_date=$(date -u -d '7 days ago' +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v-7d +%Y-%m-%dT%H:%M:%SZ)

            # Fetch recent commits
            local commits
            commits=$(gh api "repos/$repo/commits?since=$since_date" --jq '.[].sha' 2>/dev/null | head -5 || echo "")

            if [[ -n "$commits" ]]; then
              # Get diff summary for latest commit
              local latest_sha
              latest_sha=$(echo "$commits" | head -1)
              diff_output=$(gh api "repos/$repo/commits/$latest_sha" --jq '.files[] | "- \(.filename): \(.additions) additions, \(.deletions) deletions"' 2>/dev/null | head -20 || echo "")
            fi

            echo "$diff_output"
          }

          # Function to check sources in a tier
          check_tier() {
            local tier="$1"
            local sources
            sources=$(jq -r ".sources[\"$tier\"] | keys[]" "$BASELINES_FILE")

            for source in $sources; do
              local url
              local baseline_hash
              local rules
              local github_repo

              url=$(jq -r ".sources[\"$tier\"][\"$source\"].url" "$BASELINES_FILE")
              baseline_hash=$(jq -r ".sources[\"$tier\"][\"$source\"].hash" "$BASELINES_FILE")
              rules=$(jq -r ".sources[\"$tier\"][\"$source\"].rules // [] | join(\", \")" "$BASELINES_FILE")
              github_repo=$(jq -r ".sources[\"$tier\"][\"$source\"].github_repo // empty" "$BASELINES_FILE")

              echo "Checking: $source ($url)"

              current_hash=$(compute_hash "$url")

              if [[ "$current_hash" == "FETCH_FAILED" ]]; then
                echo "  WARNING: Failed to fetch $source"
                DRIFT_REPORT="${DRIFT_REPORT}\n- **$source**: Failed to fetch (may be temporary)"
                continue
              fi

              if [[ "$current_hash" == "INVALID_URL" ]]; then
                echo "  ERROR: Invalid URL for $source (must be https://)"
                DRIFT_REPORT="${DRIFT_REPORT}\n- **$source**: Invalid URL (must be https://)"
                continue
              fi

              # Store new hash for potential baseline update
              NEW_HASHES="${NEW_HASHES}${tier}|${source}|${current_hash}\n"

              if [[ -z "$baseline_hash" ]]; then
                echo "  INFO: No baseline hash set for $source (first run)"
                DRIFT_REPORT="${DRIFT_REPORT}\n- **$source**: No baseline (initial hash: ${current_hash:0:12}...)"
                DRIFT_DETECTED=true
              elif [[ "$current_hash" != "$baseline_hash" ]]; then
                echo "  DRIFT DETECTED: $source"
                echo "    Baseline: ${baseline_hash:0:12}..."
                echo "    Current:  ${current_hash:0:12}..."

                DRIFT_REPORT="${DRIFT_REPORT}\n### $source ($tier)"
                DRIFT_REPORT="${DRIFT_REPORT}\n- **URL**: $url"
                DRIFT_REPORT="${DRIFT_REPORT}\n- **Previous hash**: \`${baseline_hash:0:12}...\`"
                DRIFT_REPORT="${DRIFT_REPORT}\n- **Current hash**: \`${current_hash:0:12}...\`"

                if [[ -n "$rules" ]]; then
                  DRIFT_REPORT="${DRIFT_REPORT}\n- **Affected rules**: $rules"
                fi

                # Fetch GitHub diff if repo is available
                if [[ -n "$github_repo" ]]; then
                  echo "  Fetching GitHub diff for $github_repo..."
                  local diff_info
                  diff_info=$(fetch_github_diff "$github_repo")
                  if [[ -n "$diff_info" ]]; then
                    DRIFT_REPORT="${DRIFT_REPORT}\n- **Recent changes in repo**:"
                    DRIFT_REPORT="${DRIFT_REPORT}\n\`\`\`"
                    DRIFT_REPORT="${DRIFT_REPORT}\n$diff_info"
                    DRIFT_REPORT="${DRIFT_REPORT}\n\`\`\`"
                  fi
                fi

                DRIFT_REPORT="${DRIFT_REPORT}\n"
                DRIFT_DETECTED=true

                # Add to drift sources JSON for downstream jobs
                DRIFT_SOURCES_JSON=$(echo "$DRIFT_SOURCES_JSON" | jq --arg src "$source" --arg tier "$tier" --arg url "$url" --arg rules "$rules" '. += [{"source": $src, "tier": $tier, "url": $url, "rules": $rules}]')
              else
                echo "  OK: No change"
              fi
            done
          }

          # Check requested tiers
          if [[ "$check_s_tier" == "true" ]]; then
            echo ""
            echo "=== Checking S-tier sources ==="
            check_tier "s-tier"
          fi

          if [[ "$check_a_tier" == "true" ]]; then
            echo ""
            echo "=== Checking A-tier sources ==="
            check_tier "a-tier"
          fi

          # Output results
          echo ""
          echo "drift_detected=$DRIFT_DETECTED" >> "$GITHUB_OUTPUT"

          # Use multiline output syntax for drift report
          {
            echo "drift_report<<EOF"
            echo -e "$DRIFT_REPORT"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

          # Output drift sources JSON for downstream jobs
          echo "drift_sources=$DRIFT_SOURCES_JSON" >> "$GITHUB_OUTPUT"

          # Output new hashes if update requested
          if [[ "$UPDATE_BASELINES" == "true" ]]; then
            echo ""
            echo "=== New baseline hashes ==="
            echo -e "$NEW_HASHES"

            # Write updated baselines file
            temp_file=$(mktemp)
            cp "$BASELINES_FILE" "$temp_file"

            echo -e "$NEW_HASHES" | while IFS='|' read -r tier source hash; do
              if [[ -n "$tier" && -n "$source" && -n "$hash" ]]; then
                jq ".sources[\"$tier\"][\"$source\"].hash = \"$hash\"" "$temp_file" > "${temp_file}.new"
                mv "${temp_file}.new" "$temp_file"
              fi
            done

            # Update timestamp
            jq ".last_updated = \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"" "$temp_file" > "${temp_file}.new"
            mv "${temp_file}.new" "$temp_file"

            echo ""
            echo "Updated baselines file:"
            cat "$temp_file"
          fi

          if [[ "$DRIFT_DETECTED" == "true" ]]; then
            echo ""
            echo "DRIFT DETECTED - See report above"
          else
            echo ""
            echo "No drift detected"
          fi

      - name: Create or update drift issue
        if: steps.drift-check.outputs.drift_detected == 'true' && inputs.update_baselines != true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DRIFT_REPORT: ${{ steps.drift-check.outputs.drift_report }}
          DRIFT_SOURCES: ${{ steps.drift-check.outputs.drift_sources }}
        run: |
          set -euo pipefail

          ISSUE_TITLE="Spec Drift Detected - Review Required"
          ISSUE_LABEL="spec-drift"

          # Check if an open issue already exists
          existing_issue=$(gh issue list --state open --label "$ISSUE_LABEL" --json number --jq '.[0].number // empty')

          # Build affected rules list
          ALL_RULES=$(echo "$DRIFT_SOURCES" | jq -r '.[].rules' | tr ',' '\n' | tr -d ' ' | sort -u | tr '\n' ', ' | sed 's/,$//')

          ISSUE_BODY="## Spec Drift Sentinel Alert

          The following upstream specification sources have changed since our last baseline check.
          These changes may require updates to agnix validation rules.

          ## Changed Sources
          $DRIFT_REPORT

          ## Affected Rules Summary

          The following rules may need review: \`$ALL_RULES\`

          See each rule in:
          - [\`knowledge-base/rules.json\`](../blob/main/knowledge-base/rules.json)
          - [\`knowledge-base/VALIDATION-RULES.md\`](../blob/main/knowledge-base/VALIDATION-RULES.md)

          ## Action Required

          1. **Review each changed source** to understand what has changed
          2. **Check if rule updates are needed** in \`knowledge-base/rules.json\`
          3. **Update VALIDATION-RULES.md** if rules are modified
          4. **Update baselines** by running the workflow with \`update_baselines: true\`

          ## How to Update Baselines

          Run the spec-drift workflow manually with:
          - \`update_baselines: true\`
          - \`tier: all\` (or specific tier)

          Then copy the output JSON to \`.github/spec-baselines.json\`.

          ---
          *This issue was automatically created by the Spec Drift Sentinel workflow.*
          *Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}*"

          if [[ -n "$existing_issue" ]]; then
            echo "Updating existing issue #$existing_issue"
            # Use stdin to avoid shell interpretation of special characters
            echo "$ISSUE_BODY" | gh issue comment "$existing_issue" --body-file -
          else
            echo "Creating new drift issue"
            # Ensure label exists
            gh label create "$ISSUE_LABEL" --description "Upstream spec changes detected" --color "FFA500" 2>/dev/null || true
            # Use stdin to avoid shell interpretation of special characters
            echo "$ISSUE_BODY" | gh issue create --title "$ISSUE_TITLE" --body-file - --label "$ISSUE_LABEL"
          fi

  # Trigger Claude to analyze the drift and suggest rule updates
  trigger-claude-review:
    name: Request Claude analysis
    needs: check-drift
    if: needs.check-drift.outputs.drift_detected == 'true' && inputs.update_baselines != true
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
    steps:
      - name: Get drift issue number
        id: get-issue
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          ISSUE_NUM=$(gh issue list --repo "${{ github.repository }}" --state open --label "spec-drift" --json number --jq '.[0].number // empty')
          echo "issue_number=$ISSUE_NUM" >> "$GITHUB_OUTPUT"

      - name: Request Claude analysis
        if: steps.get-issue.outputs.issue_number != ''
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DRIFT_SOURCES: ${{ needs.check-drift.outputs.drift_sources }}
          ISSUE_NUMBER: ${{ steps.get-issue.outputs.issue_number }}
        run: |
          # Build analysis request
          SOURCES_LIST=$(echo "$DRIFT_SOURCES" | jq -r '.[] | "- \(.source) (\(.tier)): \(.url)"' | head -10)
          RULES_LIST=$(echo "$DRIFT_SOURCES" | jq -r '.[].rules' | tr ',' '\n' | tr -d ' ' | sort -u | head -20 | tr '\n' ', ' | sed 's/,$//')

          COMMENT_BODY="@claude Please analyze the spec drift detected above and help with the following:

          **Changed sources:**
          $SOURCES_LIST

          **Potentially affected rules:** \`$RULES_LIST\`

          **Analysis requested:**
          1. Fetch the current content from each changed URL
          2. Compare with our existing rules in \`knowledge-base/rules.json\`
          3. Identify if any rules need updates based on spec changes
          4. Suggest specific rule modifications if needed
          5. Note any new capabilities or deprecations in the specs

          Please provide a summary of findings and recommended actions."

          echo "$COMMENT_BODY" | gh issue comment "$ISSUE_NUMBER" --repo "${{ github.repository }}" --body-file -
